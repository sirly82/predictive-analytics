# -*- coding: utf-8 -*-
"""[Klasifikasi] BMLT_Sirly Ziadatul Mustafidah.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qi0tbNu0Pi58qMkVwLl_QD9xnmGHKak1

# **Penting**
- Pastikan Anda melakukan Run All sebelum mengirimkan submission untuk memastikan seluruh cell berjalan dengan baik.
- Hapus simbol pagar (#) jika Anda menerapkan kriteria tambahan
- Biarkan simbol pagar (#) jika Anda tidak menerapkan kriteria tambahan

# **1. Import Library**
Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import math

from xgboost import plot_importance
from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
import joblib

"""# **2. Memuat Dataset**
Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame.
"""

url = "https://raw.githubusercontent.com/sirly82/predictive-analytics/refs/heads/main/diabetes.csv"
diabetes_df = pd.read_csv(url)

diabetes_df.head()

diabetes_df.info()

diabetes_df.describe()

"""(Opsional) Memuat Dataset dan Melakukan Exploratory Data Analysis (EDA) [Skilled]

**Biarkan kosong jika tidak menerapkan kriteria skilled**
"""

# Menampilkan korelasi antar fitur (Opsional Skilled 1)
corr_matrix = diabetes_df.corr(numeric_only=True)

plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Matriks Korelasi')
plt.show()

def plot_numeric_histograms(df):
  sns.set(style="whitegrid")

  num_cols = df.select_dtypes(include='number').columns

  total_plots = len(num_cols)
  n_cols = 3
  n_rows = math.ceil(total_plots / n_cols)

  fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 5 * n_rows))
  axes = axes.flatten()

  for i, col in enumerate(num_cols):
    ax = axes[i]
    if col in num_cols:
      sns.histplot(data=df, x=col, bins=30, kde=True, ax=ax, color='skyblue')
      ax.set_title(f'Histogram: {col}', fontsize=12)
    else:
      unique_vals = df[col].nunique()
      if unique_vals <= 10:
        sns.countplot(data=df, x=col, order=df[col].value_counts().index, ax=ax, palette="Set2")
        ax.set_title(f'Countplot: {col}', fontsize=12)
        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')
      else:
        sns.countplot(data=df, y=col, order=df[col].value_counts().index[:15], ax=ax, palette="Set3")
        ax.set_title(f'Top 15: {col}', fontsize=12)

    ax.grid(True)

  for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

  fig.suptitle("Distribusi Setiap Kolom", fontsize=16)
  plt.tight_layout(rect=[0, 0, 1, 0.97])
  plt.show()

# Menampilkan histogram untuk semua kolom numerik (Opsional Skilled 1)
plot_numeric_histograms(diabetes_df)

"""# **3. Pembersihan dan Pra Pemrosesan Data**"""

diabetes_clean_df = diabetes_df.copy()

# Mengecek dataset menggunakan isnull().sum()
diabetes_clean_df.isnull().sum()

# Mengecek dataset menggunakan duplicated().sum()
duplicates = diabetes_clean_df.duplicated()
print("Jumlah baris duplikat:", duplicates.sum())

# Ganti nilai 0 menjadi NaN pada kolom yang tidak mungkin bernilai 0

cols_with_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
diabetes_df[cols_with_zero] = diabetes_df[cols_with_zero].replace(0, np.nan)

# Isi NaN dengan median
diabetes_df.fillna(diabetes_df.median(), inplace=True)

"""# **3. Data Splitting**
Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set).
"""

scaler = StandardScaler()
X = diabetes_df.drop('Outcome', axis=1)
y = diabetes_df['Outcome']

X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

"""# **4. Membangun Model Klasifikasi**
Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.

Berikut adalah rekomendasi tahapannya.
1. Menggunakan algoritma klasifikasi yaitu Logistic Regression
2. Latih model menggunakan data yang sudah dipisah.

## Logistic Regression
"""

model_lr = LogisticRegression()
model_lr.fit(X_train, y_train)

y_pred_lr = model_lr.predict(X_test)

print(confusion_matrix(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr))
print("Accuracy:", accuracy_score(y_test, y_pred_lr))

cm = confusion_matrix(y_test, y_pred_lr)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Logistic Linear")
plt.show()

joblib.dump(model_lr, 'logistic_regression_model.h5')

"""## Random Forest"""

model_rf = RandomForestClassifier(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
model_rf.fit(X_train, y_train)

y_pred_rf = model_rf.predict(X_test)

print(confusion_matrix(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))
print("Accuracy:", accuracy_score(y_test, y_pred_rf))

cm = confusion_matrix(y_test, y_pred_rf)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Random Forest")
plt.show()

joblib.dump(model_rf, 'explore_random_forest_classification.h5')

"""## Hyperparameter Tuning Model"""

param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [None, 3, 5, 10],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

model_rf2 = RandomForestClassifier(random_state=42, class_weight='balanced')

grid_search = GridSearchCV(estimator=model_rf2, param_grid=param_grid,
                           cv=5, n_jobs=-1, scoring='accuracy', verbose=1)

grid_search.fit(X_train, y_train)

print("Best parameters:", grid_search.best_params_)
print("Best score:", grid_search.best_score_)

model_best_rf = grid_search.best_estimator_

y_pred_best = model_best_rf.predict(X_test)

print(classification_report(y_test, y_pred_best))
print("Final Accuracy with Best Params:", accuracy_score(y_test, y_pred_best))

cm = confusion_matrix(y_test, y_pred_best)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Tuning Random Forest")
plt.show()

importances = model_best_rf.feature_importances_
feat_names = X.columns

plt.figure(figsize=(10,5))
plt.barh(feat_names, importances)
plt.xlabel("Feature Importance")
plt.title("Fitur paling berpengaruh dalam prediksi diabetes")
plt.show()

joblib.dump(model_best_rf, 'tuning_classification_rf.h5')

"""## Boosting Algoritma"""

model_boost = XGBClassifier(
    n_estimators=100,
    max_depth=4,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)

model_boost.fit(X_train, y_train)

y_pred_boost = model_boost.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred_boost))
print("\nClassification Report:\n", classification_report(y_test, y_pred_boost))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_boost))

cm = confusion_matrix(y_test, y_pred_boost)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - XGBoost")
plt.show()

eval_df = pd.DataFrame(index=['accuracy', 'f1'], columns=['Logistic Regression', 'Random Forest', 'XGBoost'])

eval_df.loc['accuracy', 'Logistic Regression'] = accuracy_score(y_test, model_lr.predict(X_test))
eval_df.loc['f1', 'Logistic Regression'] = f1_score(y_test, model_lr.predict(X_test))

eval_df.loc['accuracy', 'Random Forest'] = accuracy_score(y_test, model_rf.predict(X_test))
eval_df.loc['f1', 'Random Forest'] = f1_score(y_test, model_rf.predict(X_test))

eval_df.loc['accuracy', 'XGBoost'] = accuracy_score(y_test, y_pred_boost)
eval_df.loc['f1', 'XGBoost'] = f1_score(y_test, y_pred_boost)

display(eval_df)

plot_importance(model_boost)
plt.title("Feature Importance - XGBoost")
plt.show()