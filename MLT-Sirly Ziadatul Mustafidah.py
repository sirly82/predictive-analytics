# -*- coding: utf-8 -*-
"""[Klasifikasi] MLT_Sirly Ziadatul Mustafidah.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qi0tbNu0Pi58qMkVwLl_QD9xnmGHKak1

# **Penting**
- Pastikan Anda melakukan Run All sebelum mengirimkan submission untuk memastikan seluruh cell berjalan dengan baik.
- Hapus simbol pagar (#) jika Anda menerapkan kriteria tambahan
- Biarkan simbol pagar (#) jika Anda tidak menerapkan kriteria tambahan

# **1. Import Library**
Mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import math
import xgboost as xgb

from xgboost import plot_importance
from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
import joblib

"""# **2. Memuat Dataset**
Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame.
"""

url = "https://raw.githubusercontent.com/sirly82/predictive-analytics/refs/heads/main/diabetes.csv"
diabetes_df = pd.read_csv(url)

"""Menampilkan 5 data teratas"""

diabetes_df.head()

"""**Insight:** Dataset memiliki kolom-kolom seperti Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age, dan Outcome.

Menampilkan informasi detail dari dataset
"""

diabetes_df.info()

"""**Insight:**
- Dataset terdiri dari 768 baris dan 9 kolom
- Semua fitur bertipe numerik
- Tidak ada nilai null terdeteksi

Menampilkan describsi dari dataset
"""

diabetes_df.describe()

"""**Insight:**

- Terdapat nilai minimum 0 pada fitur seperti Glucose, BloodPressure, SkinThickness, dan Insulin, yang secara medis tidak masuk akal.
- Rata-rata BMI cukup tinggi (~32), menunjukkan bahwa obesitas umum dalam dataset ini.

Memuat Dataset dan Melakukan Exploratory Data Analysis (EDA)

Menampilkan korelasi antar fitur
"""

corr_matrix = diabetes_df.corr(numeric_only=True)

plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Matriks Korelasi')
plt.show()

"""**Insight:** Fitur Glucose memiliki korelasi paling kuat dengan target Outcome (~0.47)"""

def plot_numeric_histograms(df):
  sns.set(style="whitegrid")

  num_cols = df.select_dtypes(include='number').columns

  total_plots = len(num_cols)
  n_cols = 3
  n_rows = math.ceil(total_plots / n_cols)

  fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 5 * n_rows))
  axes = axes.flatten()

  for i, col in enumerate(num_cols):
    ax = axes[i]
    if col in num_cols:
      sns.histplot(data=df, x=col, bins=30, kde=True, ax=ax, color='skyblue')
      ax.set_title(f'Histogram: {col}', fontsize=12)
    else:
      unique_vals = df[col].nunique()
      if unique_vals <= 10:
        sns.countplot(data=df, x=col, order=df[col].value_counts().index, ax=ax, palette="Set2")
        ax.set_title(f'Countplot: {col}', fontsize=12)
        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')
      else:
        sns.countplot(data=df, y=col, order=df[col].value_counts().index[:15], ax=ax, palette="Set3")
        ax.set_title(f'Top 15: {col}', fontsize=12)

    ax.grid(True)

  for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

  fig.suptitle("Distribusi Setiap Kolom", fontsize=16)
  plt.tight_layout(rect=[0, 0, 1, 0.97])
  plt.show()

"""Menampilkan histogram untuk semua kolom numerik"""

plot_numeric_histograms(diabetes_df)

"""# **3. Pembersihan dan Pra Pemrosesan Data**

Membuat copy dataset diabetes_clean_df
"""

diabetes_clean_df = diabetes_df.copy()

"""Mengecek dataset menggunakan isnull().sum()"""

diabetes_clean_df.isnull().sum()

"""Mengecek duplikasi pada dataset menggunakan duplicated().sum()"""

duplicates = diabetes_clean_df.duplicated()
print("Jumlah baris duplikat:", duplicates.sum())

"""**Insight:** Tidak ada baris data yang duplikat

Mengganti nilai 0 menjadi NaN pada kolom yang tidak mungkin bernilai 0, kemudian mengisi nilai NaN dengan nilai median
"""

cols_with_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
diabetes_df[cols_with_zero] = diabetes_df[cols_with_zero].replace(0, np.nan)

diabetes_df.fillna(diabetes_df.median(), inplace=True)

"""**Insight:**

- Nilai 0 pada kolom-kolom seperti Glucose, BMI, BloodPressure, dll tidak valid secara medis sehingga perlu ditangani sebagai missing value
- Mengganti 0 dengan NaN adalah cara untuk menandai nilai yang tidak logis.
- Mengisi nilai NaN dengan nilai median karena lebih tahan terhadap outlier dibandingkan mean

# **3. Data Splitting**
Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set).
"""

scaler = StandardScaler()
X = diabetes_df.drop('Outcome', axis=1)
y = diabetes_df['Outcome']

X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

"""**Insight:**

- Standarisasi fitur untuk meningkatkan performa dan stabilitas model
- Memisahkan data uji sebelum training penting agar evaluasi model tidak bias
- Proporsi 80:20 adalah standar umum dalam pemodelan, cukup untuk melatih dan mengevaluasi secara adil

# **4. Membangun Model Klasifikasi**
Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.

Berikut adalah rekomendasi tahapannya.
1. Menggunakan algoritma klasifikasi yaitu Logistic Regression
2. Latih model menggunakan data yang sudah dipisah.

## Logistic Regression

Membuat model Logistic Regression
"""

model_lr = LogisticRegression()
model_lr.fit(X_train, y_train)

"""Menampilkan report classification dan akurasi"""

y_pred_lr = model_lr.predict(X_test)

print(classification_report(y_test, y_pred_lr))
print("Accuracy:", accuracy_score(y_test, y_pred_lr))

"""**Insight:**

- Precision
  - Kelas 0 (0.80): Dari semua yang diprediksi sebagai non-diabetes, 80% benar-benar non-diabetes
  - Kelas 1 (0.67): Dari semua yang diprediksi sebagai diabetes, hanya 67% benar-benar diabetes. Ada kesalahan dalam memprediksi diabetes (false positive cukup tinggi)

- Recall
  - Kelas 0 (0.83): Dari seluruh non-diabetes, 83% berhasil dikenali dengan benar
  - Kelas 1 (0.62): Dari seluruh pasien diabetes, hanya 62% yang berhasil dikenali. Ada cukup banyak penderita diabetes yang tidak terdeteksi (false negative tinggi)

- F1-Score merupakan rata-rata antara precision dan recall
  - Kelas 0: 0.81
  - Kelas 1: 0.64

  Untuk melihat keseimbangan performa, terutama jika distribusi data tidak seimbang

- Support menunjukkan jumlah aktual dari setiap kelas dalam data uji:
  - Kelas 0: 99 orang
  - Kelas 1: 55 orang

Menampilkan Confusion Matrix dari Logistic Linear
"""

cm = confusion_matrix(y_test, y_pred_lr)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Logistic Linear")
plt.show()

"""**Insight:**

- 82 pasien non-diabetes diprediksi benar sebagai non-diabetes (true positive)
- 17 pasien non-diabetes salah diprediksi sebagai diabetes (false positive)
- 21 pasien diabetes tidak terdeteksi alias diprediksi sebagai non-diabetes (false negative)
- 34 pasien diabetes terdeteksi benar sebagai diabetes (true negative)

Menyimpan model logistic_regression
"""

joblib.dump(model_lr, 'logistic_regression_model.h5')

"""## Random Forest

Membuat model Random Forest
"""

model_rf = RandomForestClassifier(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
model_rf.fit(X_train, y_train)

"""Menampilkan report classification dan akurasi"""

y_pred_rf = model_rf.predict(X_test)

print(classification_report(y_test, y_pred_rf))
print("Accuracy:", accuracy_score(y_test, y_pred_rf))

"""**Insight:**

- Precision
  - Kelas 0 (0.82): Dari semua yang diprediksi sebagai non-diabetes, 82% benar-benar non-diabetes
  - Kelas 1 (0.66): Dari semua yang diprediksi sebagai diabetes, hanya 66% benar-benar diabetes. Ada kesalahan dalam memprediksi diabetes (false positive cukup tinggi)

- Recall
  - Kelas 0 (0.81): Dari seluruh non-diabetes, 81% berhasil dikenali dengan benar
  - Kelas 1 (0.67): Dari seluruh pasien diabetes, hanya 67% yang berhasil dikenali. Ada cukup banyak penderita diabetes yang tidak terdeteksi (false negative tinggi)

- F1-Score merupakan rata-rata antara precision dan recall
  - Kelas 0: 0.81
  - Kelas 1: 0.67

  Untuk melihat keseimbangan performa, terutama jika distribusi data tidak seimbang

- Support menunjukkan jumlah aktual dari setiap kelas dalam data uji:
  - Kelas 0: 99 orang
  - Kelas 1: 55 orang

Menampilkan confussion Matrix dari Random Forest
"""

cm = confusion_matrix(y_test, y_pred_rf)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Random Forest")
plt.show()

"""**Insight:**

- 80 pasien non-diabetes diprediksi benar sebagai non-diabetes (true positive)
- 19 pasien non-diabetes salah diprediksi sebagai diabetes (false positive)
- 18 pasien diabetes tidak terdeteksi alias diprediksi sebagai non-diabetes (false negative)
- 37 pasien diabetes terdeteksi benar sebagai diabetes (true negative)

Menyimpan model random forest
"""

joblib.dump(model_rf, 'explore_random_forest_classification.h5')

"""## Hyperparameter Tuning Model

Mendefinisikan grid dari hyperparameter yang akan diuji menggunakan GridSearchCV
"""

param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [None, 3, 5, 10],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

"""**Insight:**
Menentukan berbagai kombinasi nilai hyperparameter untuk Random Forest agar bisa diuji coba dan dicari konfigurasi terbaik yang meningkatkan performa model

Membuat objek RandomForest dengan penyeimbangan bobot kelas (class_weight='balanced') untuk menangani data yang tidak seimbang
"""

model_rf2 = RandomForestClassifier(random_state=42, class_weight='balanced')

"""**Insight:**
Pengaturan class_weight balance digunakan untuk mengatasi ketidakseimbangan data kelas diabetes dan non-diabetes sehingga model tidak bias terhadap kelas mayoritas

Melakukan pencarian grid (GridSearchCV) dengan 5-fold cross-validation untuk menemukan kombinasi parameter terbaik berdasarkan skor akurasi
"""

grid_search = GridSearchCV(estimator=model_rf2, param_grid=param_grid,
                           cv=5, n_jobs=-1, scoring='accuracy', verbose=1)

"""**Insight:**
GridSearchCV dengan 5-fold CV dipakai untuk mengevaluasi berbagai kombinasi hyperparameter secara menyeluruh

Melatih model pada data latih
"""

grid_search.fit(X_train, y_train)

"""Menampilkan kombinasi parameter terbaik dan akurasi rata-rata cross-validation tertinggi"""

print("Best parameters:", grid_search.best_params_)
print("Best score:", grid_search.best_score_)

"""**Insight:**
Model mampu memprediksi dengan benar sekitar 77.85% dari data pelatihan

Menggunakan model terbaik dari hasil GridSearchCV untuk prediksi pada data uji
"""

model_best_rf = grid_search.best_estimator_
y_pred_best = model_best_rf.predict(X_test)

"""Menampilkan metrik evaluasi"""

print(classification_report(y_test, y_pred_best))
print("Final Accuracy with Best Params:", accuracy_score(y_test, y_pred_best))

"""**Insight:**

- Precision
  - Kelas 0 (0.85): Dari semua yang diprediksi sebagai non-diabetes, 85% benar-benar non-diabetes
  - Kelas 1 (0.62): Dari semua yang diprediksi sebagai diabetes, hanya 62% benar-benar diabetes. Ada kesalahan dalam memprediksi diabetes (false positive cukup tinggi)

- Recall
  - Kelas 0 (0.77): Dari seluruh non-diabetes, 77% berhasil dikenali dengan benar
  - Kelas 1 (0.76): Dari seluruh pasien diabetes, 76% berhasil dikenali. Ini sudah meningkat sedikit dari model sebelumnya

- F1-Score merupakan rata-rata antara precision dan recall
  - Kelas 0: 0.71
  - Kelas 1: 0.68

  Untuk melihat keseimbangan performa, terutama jika distribusi data tidak seimbang

- Support menunjukkan jumlah aktual dari setiap kelas dalam data uji:
  - Kelas 0: 99 orang
  - Kelas 1: 55 orang

Membuat visualisasi confusion matrix untuk memahami performa prediksi model
"""

cm = confusion_matrix(y_test, y_pred_best)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Tuning Random Forest")
plt.show()

"""**Insight:**

- 73 pasien non-diabetes diprediksi benar sebagai non-diabetes (true positive)
- 26 pasien non-diabetes salah diprediksi sebagai diabetes (false positive)
- 13 pasien diabetes tidak terdeteksi alias diprediksi sebagai non-diabetes (false negative)
- 42 pasien diabetes terdeteksi benar sebagai diabetes (true negative)

Menampilkan grafik dari pentingnya tiap fitur dalam prediksi menurut model Random Forest
"""

importances = model_best_rf.feature_importances_
feat_names = X.columns

plt.figure(figsize=(10,5))
plt.barh(feat_names, importances)
plt.xlabel("Feature Importance")
plt.title("Fitur paling berpengaruh dalam prediksi diabetes")
plt.show()

"""**Insight:**
3 fitur yang sangat mempengaruhi prediksi diabetes adalah glucose(+25%), BMI(+15%), dan age(~14%)

Menyimpan model terbaik Random Forest setelah melakukan tuning
"""

joblib.dump(model_best_rf, 'tuning_classification_rf.h5')

"""## Boosting Algoritma

Membuat dan melatih model XGBoost
"""

model_boost = XGBClassifier(
    n_estimators=100,
    max_depth=4,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)

model_boost.fit(X_train, y_train)

"""Memprediksi dan mengevaluasi performa XGBoost"""

y_pred_boost = model_boost.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred_boost))
print("\nClassification Report:\n", classification_report(y_test, y_pred_boost))

"""Visualisasi confusion matrix untuk model XGBoost

**Insight:**

- Precision
  - Kelas 0 (0.83): Dari semua yang diprediksi sebagai non-diabetes, 83% benar-benar non-diabetes
  - Kelas 1 (0.65): Dari semua yang diprediksi sebagai diabetes, hanya 65% benar-benar diabetes. Ada kesalahan dalam memprediksi diabetes (false positive cukup tinggi)

- Recall
  - Kelas 0 (0.79): Dari seluruh non-diabetes, 77% berhasil dikenali dengan benar
  - Kelas 1 (0.71): Dari seluruh pasien diabetes, hanya 71% berhasil dikenali

- F1-Score merupakan rata-rata antara precision dan recall
  - Kelas 0: 0.81
  - Kelas 1: 0.68

  Untuk melihat keseimbangan performa, terutama jika distribusi data tidak seimbang

- Support menunjukkan jumlah aktual dari setiap kelas dalam data uji:
  - Kelas 0: 99 orang
  - Kelas 1: 55 orang
"""

cm = confusion_matrix(y_test, y_pred_boost)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - XGBoost")
plt.show()

"""**Insight:**

- 78 pasien non-diabetes diprediksi benar sebagai non-diabetes (true positive)
- 21 pasien non-diabetes salah diprediksi sebagai diabetes (false positive)
- 16 pasien diabetes tidak terdeteksi alias diprediksi sebagai non-diabetes (false negative)
- 39 pasien diabetes terdeteksi benar sebagai diabetes (true negative)

Membuat DataFrame untuk membandingkan akurasi dan f1-score dari ketiga model
"""

eval_df = pd.DataFrame(index=['accuracy', 'f1'], columns=['Logistic Regression', 'Random Forest', 'XGBoost'])

eval_df.loc['accuracy', 'Logistic Regression'] = accuracy_score(y_test, model_lr.predict(X_test))
eval_df.loc['f1', 'Logistic Regression'] = f1_score(y_test, model_lr.predict(X_test))

eval_df.loc['accuracy', 'Random Forest'] = accuracy_score(y_test, model_rf.predict(X_test))
eval_df.loc['f1', 'Random Forest'] = f1_score(y_test, model_rf.predict(X_test))

eval_df.loc['accuracy', 'XGBoost'] = accuracy_score(y_test, y_pred_boost)
eval_df.loc['f1', 'XGBoost'] = f1_score(y_test, y_pred_boost)

display(eval_df)

"""**Insight:**

- Akurasi:
  - Ketiga model memiliki performa akurasi yang cukup mirip, yaitu sekitar 75-76%. Random Forest dan XGBoost sama-sama di angka ~75.97% yang sedikit lebih baik daripada Logistic Regression di 75.32%.
  - Random Forest dan XGBoost sedikit lebih baik dalam menangkap pola data dibandingkan Logistic Regression

- F1-Score:
  - F1-score lebih menggambarkan keseimbangan antara kesalahan positif dan negatif, penting untuk dataset dengan distribusi kelas yang tidak seimbang
  - XGBoost menunjukkan nilai F1-score tertinggi yaitu 0.68, diikuti oleh Random Forest 0.67, dan Logistic Regression 0.64.
  - Dengan begitu, dapat dikatakan XGBoost lebih baik dalam menangani kelas positif (pasien diabetes) dengan keseimbangan antara mengenali benar kasus positif dan menghindari false alarm, dibandingkan dua model lain

Menampilkan pentingnya fitur menurut model XGBoost
"""

dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=X.columns.tolist())
dtest = xgb.DMatrix(X_test, label=y_test, feature_names=X.columns.tolist())

params = {
    'objective': 'binary:logistic',
    'eval_metric': 'logloss',
    'max_depth': 4,
    'learning_rate': 0.1,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'seed': 42
}

model_boost = xgb.train(params, dtrain, num_boost_round=100)

xgb.plot_importance(model_boost)
plt.show()

"""**Insight:**

- Feautures yang sangat mempengaruhi menurut XGBoost adalah:
  - DiabetesPedigreeFunction : 184.0
  - Glucose : 179.0
  - BMI : 161.0
  - Age : 142.0
"""